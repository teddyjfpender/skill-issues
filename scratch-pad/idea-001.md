# Idea 1
we want to benchmark the value of a skill.
we can do this by re-running the same configuration with and without skills and then perform a regression on how the skill has helped or not helped. regression should be on the predicted time to complete for the configuration and or or number of tokens or other success metrics.

# Idea 2
we also want to track how many iterations each step took. so we can create step function line charts, if an iteration succeeds then it goes up, if it doesn't then it continues one across flat. 
we could also show when the orchestrator (e.g. cladue code) did something - that's a little tough.